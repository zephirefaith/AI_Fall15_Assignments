{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the ipython notebook you should use as a template for your agent. Your task for this assignment is to implement a winning AI for the game of Isolation, as specified in the assignment pdf you have been issued.\n",
    "\n",
    "The following random agent just selects a move out of the set of legal moves. Note that your agent, when asked for a move, is already provided with the set of moves available to it. This is done for your convenience. If your agent attempts to perform an illegal move, it will lose, so please refrain from doing so. It is also provided with a function that, when invoked, returns the amount of time left for your agent to make its move. If your agent fails to make a move in the alloted time, it will lose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "class RandomPlayer():\n",
    "    \"\"\"Player that chooses a move randomly.\"\"\"\n",
    "    def move(self, game, legal_moves, time_left):\n",
    "        if not legal_moves: return (-1,-1)\n",
    "        return legal_moves[randint(0,len(legal_moves)-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are functions that might be useful to you in developing your agent:\n",
    "\n",
    "    game.get_legal_moves(): Returns a list of legal moves for the active player.\n",
    "\n",
    "    game.get_opponent_moves(): Returns a list of legal moves for the inactive player.\n",
    "\n",
    "    game.forecast_move(move): This returns a new board, whose state is the result of making the move specified on the current board.\n",
    "\n",
    "    game.get_state(): This returns a 2D array containing a copy of the explicit state of the board. \n",
    "    \n",
    "    game.is_winner(player): Returns whether your player agent has won.\n",
    "    \n",
    "    game.is_opponent_winner(player): Returns whether your player's opponent has won.    \n",
    "    \n",
    "    game.print_board(): Returns a string representation of the game board. This should be useful for debugging.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HumanPlayer():\n",
    "    \"\"\"Player that chooses a move according to\n",
    "    user's input.\"\"\"\n",
    "    def move(self, game, legal_moves, time_left):\n",
    "        print('\\t'.join(['[%d] %s'%(i,str(move)) for i,move in enumerate(legal_moves)] ))\n",
    "        \n",
    "        valid_choice = False\n",
    "        while not valid_choice:\n",
    "            try:\n",
    "                index = int(raw_input('Select move index:'))\n",
    "                valid_choice = 0 <= index < len(legal_moves)\n",
    "\n",
    "                if not valid_choice:\n",
    "                    print('Illegal move! Try again.')\n",
    "            \n",
    "            except ValueError:\n",
    "                print('Invalid index! Try again.')\n",
    "        return legal_moves[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first part of the assignment you are expected to implement. It is the evaluation function we've been using in class. The score of a specified game state is just the number of moves open to the active player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OpenMoveEvalFn():\n",
    "    \n",
    "    def score(self, game, maximizing_player):\n",
    "        if maximizing_player:\n",
    "            eval_func = len(game.get_legal_moves())\n",
    "        else:\n",
    "            eval_func = len(game.get_opponent_moves())\n",
    "        return eval_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The following is a \n",
    "    Custom evaluation function that acts\n",
    "    however you think it should. This is not\n",
    "    required but highly encouraged if you\n",
    "    want to build the best AI possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomEvalFn():\n",
    "\n",
    "    def score(self, game, maximizing_player):\n",
    "        #maximize your own moves and minimize opponents moves\n",
    "        if maximizing_player:\n",
    "            my_moves = len(game.get_legal_moves())\n",
    "            opponents_moves = len(game.get_opponent_moves())\n",
    "        else:\n",
    "            opponents_moves = len(game.get_legal_moves())\n",
    "            my_moves = len(game.get_opponent_moves())\n",
    "            \n",
    "        #maximize this\n",
    "        eval_func = my_moves - opponents_moves\n",
    "        return eval_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a Player below that chooses a move using \n",
    "    your evaluation function and \n",
    "    a depth-limited minimax algorithm \n",
    "    with alpha-beta pruning.\n",
    "    You must finish and test this player\n",
    "    to make sure it properly uses minimax\n",
    "    and alpha-beta to return a good move\n",
    "    in less than 500 milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CustomPlayer():\n",
    "    \n",
    "    def __init__(self, search_depth=15, eval_fn=CustomEvalFn(), threshold = 50):\n",
    "        self.eval_fn = eval_fn\n",
    "        self.search_depth = search_depth\n",
    "        self.thresh = threshold\n",
    "\n",
    "    def move(self, game, legal_moves, time_left):\n",
    "\n",
    "        if game.move_count<2:\n",
    "            return legal_moves[randint(0,len(legal_moves)-1)]\n",
    "        best_move = self.alphabeta_id(game, time_left, self.search_depth)\n",
    "        # you will eventually replace minimax with alpha-beta\n",
    "        return best_move\n",
    "\n",
    "    def utility(self, game, maximizing_player):\n",
    "        \n",
    "        if game.is_winner(self):\n",
    "            return 50000\n",
    "\n",
    "        if game.is_opponent_winner(self):\n",
    "            return -50000\n",
    "\n",
    "        return self.eval_fn.score(game, maximizing_player)\n",
    "    \n",
    "    \n",
    "    def minimax(self, game, time_left, depth=float(\"inf\"), maximizing_player=True):\n",
    "        #terminal states\n",
    "        #if maximizing_player and realize opponent has won\n",
    "        #if minimizing player and realize max has won\n",
    "        if (maximizing_player and game.is_opponent_winner(self)) or (not maximizing_player and game.is_winner(self)):\n",
    "            return ((-1,-1), self.utility(game, maximizing_player))\n",
    "        #if realize that time_left isn't much, we have an arbitrary threshold of 50 ms here/max depth is reached\n",
    "        if depth==0 or time_left()<self.thresh:\n",
    "            return ((-1,-1), self.utility(game, maximizing_player))\n",
    "        \n",
    "        #get actions\n",
    "        actions = game.get_legal_moves()\n",
    "        best_move = (-1,-1)\n",
    "        \n",
    "        #if maximizing player, get minimax value for all actions and choose the move which has maxMIN value  \n",
    "        if maximizing_player:\n",
    "            best_val = float(\"-inf\")\n",
    "            for a in actions:\n",
    "                _, score_of_action = self.minimax(game.forecast_move(a), time_left, depth-1, False);\n",
    "                best_move, best_val = (a, score_of_action) if score_of_action>=best_val else (best_move, best_val)\n",
    "                if time_left()<self.thresh:\n",
    "                    return (best_move, best_val)\n",
    "        #if minimizing player find minimax value for all actions and choose one which has minMAX value\n",
    "        else:\n",
    "            best_val = float(\"inf\")\n",
    "            for a in actions:\n",
    "                _, score_of_action = self.minimax(game.forecast_move(a), time_left, depth-1, True);\n",
    "                best_move, best_val = (a, score_of_action) if score_of_action<=best_val else (best_move, best_val)\n",
    "                if time_left()<self.thresh:\n",
    "                    return (best_move, best_val)\n",
    "                \n",
    "        return (best_move, best_val)   \n",
    "    \n",
    "    \n",
    "    def alphabeta(self, game, time_left, depth=float(\"inf\"), alpha=float(\"-inf\"), beta=float(\"inf\"), maximizing_player=True):\n",
    "        #terminal states\n",
    "        #if maximizing_player and realize opponent has won\n",
    "        #if minimizing player and realize max has won\n",
    "        if (maximizing_player and game.is_opponent_winner(self)) or (not maximizing_player and game.is_winner(self)):\n",
    "            return ((-1,-1), self.utility(game, maximizing_player))\n",
    "        #if realize that time_left isn't much, we have an arbitrary threshold of 75 ms here/max depth is reached\n",
    "        if depth==0 or time_left()<self.thresh:\n",
    "            return ((-1,-1), self.utility(game, maximizing_player))\n",
    "        \n",
    "        #get actions\n",
    "        actions = game.get_legal_moves()\n",
    "        best_move = (-1,-1)\n",
    "        \n",
    "        #if maximizing player, get alphabeta value for all actions and choose the move \n",
    "        #which has max value plus prune those which do not adher to alphabeta limits\n",
    "        if maximizing_player:\n",
    "            best_val = float(\"-inf\")\n",
    "            for a in actions:\n",
    "                _, score_of_action = self.alphabeta(game.forecast_move(a), time_left, depth-1, alpha, beta, False);\n",
    "                if score_of_action>best_val:\n",
    "                    best_move = a\n",
    "                    best_val = score_of_action\n",
    "                if best_val>beta:\n",
    "                    return a, best_val\n",
    "                alpha = max(alpha, best_val)\n",
    "                if alpha>=beta:\n",
    "                    return a, alpha\n",
    "                if time_left()<self.thresh:\n",
    "                    return (best_move, best_val)\n",
    "        else:\n",
    "            best_val = float(\"inf\")\n",
    "            for a in actions:\n",
    "                _, score_of_action = self.alphabeta(game.forecast_move(a), time_left, depth-1, alpha, beta, True);\n",
    "                if score_of_action<best_val:\n",
    "                    best_move = a\n",
    "                    best_val = score_of_action\n",
    "                if best_val<alpha:\n",
    "                    return a, best_val\n",
    "                beta = min(beta, best_val)\n",
    "                if beta<=alpha:\n",
    "                    return a, beta\n",
    "                if time_left()<self.thresh:\n",
    "                    return (best_move, best_val)\n",
    "        \n",
    "        return (best_move, best_val)\n",
    "    \n",
    "    def alphabeta_id(self, game, time_left, max_depth):\n",
    "    \n",
    "        for depth in range(1, max_depth):\n",
    "            best_move, _ = self.alphabeta(game, time_left, depth)\n",
    "            if time_left()<self.thresh:\n",
    "                break\n",
    "        return (best_move)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are some basic tests you can use to sanity-check your code. You will also be provided with a test server to which you will be able to submit your agents later this week. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "1 | 0 | 0 | 0 | 0 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 2 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "1 | 0 | 0 | 0 | 0 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 2 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | 1 | 0 | 0 | 0 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 0 | 2 | \n",
      "0 | 0 | 0 | X | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | 1 | 0 | 0 | 0 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 0 | 2 | \n",
      "0 | 0 | 0 | X | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | 1 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 2 | X | \n",
      "0 | 0 | 0 | X | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | 1 | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | 2 | X | \n",
      "0 | 1 | 0 | X | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 0 | 0 | X | X | \n",
      "0 | 1 | 0 | X | 0 | \n",
      "0 | 2 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 1 | 0 | X | X | \n",
      "0 | X | 0 | X | 0 | \n",
      "0 | 2 | 0 | 0 | 0 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | 1 | 0 | X | X | \n",
      "0 | X | 0 | X | 0 | \n",
      "0 | X | 0 | 0 | 2 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | 1 | X | 0 | \n",
      "0 | X | 0 | 0 | 2 | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | 1 | X | 0 | \n",
      "0 | X | 2 | 0 | X | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | X | X | 0 | \n",
      "0 | X | 2 | 1 | X | \n",
      "0 | 0 | 0 | 0 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | X | X | 0 | \n",
      "0 | X | X | 1 | X | \n",
      "0 | 0 | 0 | 2 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | X | X | 0 | \n",
      "0 | X | X | X | X | \n",
      "0 | 0 | 1 | 2 | 0 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | X | X | 0 | \n",
      "0 | X | X | X | X | \n",
      "0 | 0 | 1 | X | 2 | \n",
      "X | X | 0 | 0 | X | \n",
      "\n",
      "####################\n",
      "####################\n",
      "0 | X | 0 | X | X | \n",
      "0 | X | X | X | 0 | \n",
      "0 | X | X | X | X | \n",
      "0 | 0 | X | X | 2 | \n",
      "X | X | 0 | 1 | X | \n",
      "\n",
      "####################\n",
      "Illegal move at -1,-1.\n",
      "Player 1 wins.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Example test you can run\n",
    "to make sure your AI does better\n",
    "than random.\"\"\"\n",
    "from isolation import Board\n",
    "if __name__ == \"__main__\":\n",
    "    r = RandomPlayer()\n",
    "    h = CustomPlayer()\n",
    "    game = Board(h,r)\n",
    "    game.play_isolation(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score() takes exactly 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-3eac1772c942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# so board gets a score of 16\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOpenMoveEvalFn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'This board has a score of %s.'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_board\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: score() takes exactly 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "\"\"\"Example test you can run\n",
    "to make sure your basic evaluation\n",
    "function works.\"\"\"\n",
    "from isolation import Board\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sample_board = Board(RandomPlayer(),RandomPlayer())\n",
    "    # setting up the board as though we've been playing\n",
    "    sample_board.move_count = 3\n",
    "    sample_board.__active_player__ = 0 # player 1 = 0, player 2 = 1\n",
    "    # 1st board = 16 moves\n",
    "    sample_board.__board_state__ = [\n",
    "                [0,2,0,0,0],\n",
    "                [0,0,0,0,0],\n",
    "                [0,0,1,0,0],\n",
    "                [0,0,0,0,0],\n",
    "                [0,0,0,0,0]]\n",
    "    sample_board.__last_player_move__ = [(2,2),(0,1)]\n",
    "\n",
    "    # player 1 should have 16 moves available,\n",
    "    # so board gets a score of 16\n",
    "    h = OpenMoveEvalFn()\n",
    "    print('This board has a score of %s.'%(h.score(sample_board)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
