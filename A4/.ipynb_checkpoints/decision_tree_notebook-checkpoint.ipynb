{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Decision Tree Learning\n",
    "\n",
    "In this assignment, you will work with a class of reinforcement learning agents called decision trees to attempt to classify features according to some decision boundary.\n",
    "\n",
    "\n",
    "This assignment is due on T-Square on November 3 by 9:35 AM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction:\n",
    "-------\n",
    "\n",
    "For this assignment we're going to need an explicit way to make structured decisions. The following is a decision node- a class representing some atomic choice in a binary decision graph. It can represent a class label (i.e. a final decision) or a binary decision to guide the us through a flow-chart to arrive at a decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionNode():\n",
    "\n",
    "    def __init__(self, left, right, decision_function,class_label=None):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.decision_function = decision_function\n",
    "        self.class_label = class_label\n",
    "\n",
    "    def decide(self, feature):\n",
    "        if self.class_label is not None:\n",
    "            return self.class_label\n",
    "        \n",
    "        return self.left.decide(feature) if self.decision_function(feature) else self.right.decide(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Warmup: Building a tree by hand\n",
    "--------\n",
    "20 pts.\n",
    "\n",
    "In the below code block, construct a tree of decision nodes by hand in order to classify the data below. Select tests to be as small as possible (in terms of attributes), breaking ties among tests with the same number of attributes by selecting the one that classifies the greatest number of examples correctly. If multiple tests have the same number of attributes and classift the same number of examples, then break the tie using attributes with lower index numbers (e.g. select $A_1$ over $A_2$)\n",
    "\n",
    "| Datum  | $A_1$ | $A_2$ | $A_3$ | $A_4$ |  y  |\n",
    "| -------| :---: | :---: | :---: | :---: | ---:|\n",
    "| $x_1$  |   1   |   0   |   0   |   0   |  1  |\n",
    "| $x_2$  |   1   |   0   |   1   |   1   |  1  |\n",
    "| $x_3$  |   0   |   1   |   0   |   0   |  1  |\n",
    "| $x_4$  |   0   |   1   |   1   |   0   |  0  |\n",
    "| $x_5$  |   1   |   1   |   0   |   1   |  1  |\n",
    "| $x_6$  |   0   |   1   |   0   |   1   |  0  |\n",
    "| $x_7$  |   0   |   0   |   1   |   1   |  1  |\n",
    "| $x_8$  |   0   |   0   |   1   |   0   |  0  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "examples = [[1,0,0,0],\n",
    "            [1,0,1,1],\n",
    "            [0,1,0,0],\n",
    "            [0,1,1,0],\n",
    "            [1,1,0,1],\n",
    "            [0,1,0,1],\n",
    "            [0,0,1,1],\n",
    "            [0,0,1,0]]\n",
    "\n",
    "classes = [1,1,1,0,1,0,1,0]\n",
    "\n",
    "# Constructing nodes one at a time,\n",
    "# build a decision tree as specified above.\n",
    "# There exists a correct tree with less than 6 nodes.\n",
    "\n",
    "decision_tree_label_1 = DecisionNode(None, None, None, 1)\n",
    "decision_tree_label_0 = DecisionNode(None, None, None, 0)\n",
    "a3Eqa4Func = lambda feat: feat[2]==feat[3]\n",
    "decision_tree_test2 = DecisionNode(decision_tree_label_1, decision_tree_label_0, a3Eqa4Func)\n",
    "a1Func = lambda feat: feat[0]==1\n",
    "decision_tree_root = DecisionNode(decision_tree_label_1, decision_tree_test2, a1Func)\n",
    "\n",
    "for i in examples:\n",
    "    print decision_tree_root.decide(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1b: Validation\n",
    "--------\n",
    "\n",
    "Now that we have a decision tree, we're going to need some way to evaluate its performance. In most cases we'd reserve a portion of the training data for evaluation, or use cross validation, bot for now let's just see how your tree does on the provided examples. In the stubbed out code below, fill out the methods to compute accuracy, precision, recall, and the confusion matrix for your classifier output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "[[5, 0], [0, 3]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(classifier_output, true_labels):\n",
    "    #TODO output should be [[true_positive, false_negative], [false_positive, true_negative]]\n",
    "    truePos = 0\n",
    "    falsePos = 0\n",
    "    trueNeg = 0\n",
    "    falseNeg = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if classifier_output[i]==1:\n",
    "            if classifier_output[i] == true_labels[i]:\n",
    "                truePos += 1\n",
    "            if classifier_output[i] != true_labels[i]:\n",
    "                falsePos += 1\n",
    "        elif true_labels[i]==1 and classifier_output[i]==0:\n",
    "                falseNeg += 1\n",
    "        elif true_labels[i]==0 and classifier_output[i]==0:\n",
    "            trueNeg += 1\n",
    "            \n",
    "    return [[truePos, falseNeg],[falsePos,trueNeg]]\n",
    "\n",
    "def precision(classifier_output, true_labels):\n",
    "    #TODO precision is measured as: true_positive/ (true_positive + false_positive)\n",
    "    truePos = 0\n",
    "    falsePos = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if classifier_output[i]==1:\n",
    "            if classifier_output[i] == true_labels[i]:\n",
    "                truePos += 1\n",
    "            if classifier_output[i] != true_labels[i]:\n",
    "                falsePos += 1\n",
    "    if truePos>0 or falsePos>0:\n",
    "        return 1.0*truePos/(truePos+falsePos)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def recall(classifier_output, true_labels):\n",
    "    #TODO: recall is measured as: true_positive/ (true_positive + false_negative)\n",
    "    truePos = 0\n",
    "    falseNeg = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        if true_labels[i]==1:\n",
    "            if classifier_output[i] == true_labels[i]:\n",
    "                truePos += 1\n",
    "            if classifier_output[i] != true_labels[i]:\n",
    "                falseNeg += 1\n",
    "    if truePos>0 or falseNeg>0:\n",
    "        return 1.0*truePos/(truePos+falseNeg)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def accuracy(classifier_output, true_labels):\n",
    "    #TODO accuracy is measured as:  correct_classifications / total_number_examples\n",
    "    trueCount = 0\n",
    "    newList = zip(classifier_output, true_labels)\n",
    "    for i,j in newList:\n",
    "        if i==j:\n",
    "            trueCount += 1\n",
    "    \n",
    "    if len(true_labels)>0:\n",
    "        return 1.0*trueCount/len(true_labels)\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "classifier_output = [decision_tree_root.decide(example) for example in examples]\n",
    "\n",
    "# Make sure your hand-built tree is 100% accurate.\n",
    "p1_accuracy = accuracy( classifier_output, classes )\n",
    "p1_precision = precision(classifier_output, classes)\n",
    "p1_recall = recall(classifier_output, classes)\n",
    "p1_confusion_matrix = confusion_matrix(classifier_output, classes)\n",
    "\n",
    "print p1_accuracy\n",
    "print p1_precision\n",
    "print p1_confusion_matrix\n",
    "print p1_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Decision Tree Learning\n",
    "-------\n",
    "40 pts.\n",
    "\n",
    "As the number of examples we have grows, it rapidly becomes impractical to build these trees by hand, so it becomes necessary to specify a procedure by which we can automagically construct these trees.\n",
    "\n",
    "For starters, let's consider the following algorithm (a variation of C4.5) for the construction of a decision tree from a given set of examples:\n",
    "\n",
    "    1) Check for base cases: \n",
    "         a)If all elements of a list are of the same class, return a leaf node with the appropriate class label.\n",
    "         b)If a specified depth limit is reached, return a leaf labeled with the most frequent class.\n",
    "\n",
    "    2) For each attribute alpha: evaluate the normalized information gain gained by splitting on alpha\n",
    "\n",
    "    3) Let alpha_best be the attribute with the highest normalized information gain\n",
    "\n",
    "    4) Create a decision node that splits on alpha_best\n",
    "\n",
    "    5) Recur on the sublists obtained by splitting on alpha_best, and add those nodes as children of node\n",
    "\n",
    "In the \\_\\_build_tree\\__ method below implement the above algorithm. In the \"classify\" method below, write a function to produce classifications for a list of features once your decision tree has been build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import operator\n",
    "import numpy\n",
    "import sys\n",
    "\n",
    "def entropy(class_vector):\n",
    "    # TODO: Compute the Shannon entropy for a vector of classes\n",
    "    # Note: Classes will be given as either a 0 or a 1.\n",
    "    zeroCount = 0\n",
    "    oneCount = 0\n",
    "    for i in class_vector:\n",
    "        if i == 1:\n",
    "            oneCount += 1\n",
    "        else:\n",
    "            zeroCount += 1\n",
    "    totCount = oneCount + zeroCount\n",
    "    oneFrac = float(1.0*oneCount/totCount)\n",
    "    zeroFrac = float(1.0*zeroCount/totCount)\n",
    "    if oneFrac>0.0 and zeroFrac>0.0:\n",
    "        totEntropy = -1.0*((oneFrac)*math.log(oneFrac)+(zeroFrac)*math.log(zeroFrac))\n",
    "    else:\n",
    "        totEntropy = 0\n",
    "    \n",
    "    return totEntropy\n",
    "    \n",
    "def information_gain(previous_classes, current_classes ):\n",
    "    # TODO: Implement information gain\n",
    "    entropyOrig = entropy(previous_classes)\n",
    "    entropyNew = entropy(current_classes[0]) + entropy(current_classes[1])\n",
    "    return entropyOrig - entropyNew\n",
    "\n",
    "class DecisionTree():\n",
    "\n",
    "    def __init__(self, depth_limit=float('inf')):\n",
    "        self.root = None\n",
    "        self.depth_limit = depth_limit\n",
    "        self.numAttr = 0\n",
    "        #self.ignoreAttr = []\n",
    "\n",
    "    def fit(self, features, classes):\n",
    "        self.numAttr = len(features[0])\n",
    "        self.root = self.__build_tree__(features, classes)\n",
    "        #self.ignoreAttr = []\n",
    "\n",
    "    def __build_tree__(self, features, classes, depth=0, mode=0, attr_subsample_rate=0):\n",
    "        #TODO Implement the algorithm as specified above\n",
    "        #check for base cases\n",
    "        #if len(self.ignoreAttr)==self.numAttr:\n",
    "         #   sys.exit(\"Depth more than number of attributes!\")\n",
    "        if depth == self.depth_limit:\n",
    "            zeroCount = 0\n",
    "            oneCount = 0\n",
    "            for i in classes:\n",
    "                if i == 1:\n",
    "                    oneCount += 1\n",
    "                else:\n",
    "                    zeroCount += 1\n",
    "            maxLabel = 0 if zeroCount>oneCount else 1\n",
    "            #print str(['reached max depth, maxLabel is: ', maxLabel,'. counts are (0/1): ',zeroCount,'/',oneCount])\n",
    "            return DecisionNode(None, None, None, maxLabel)\n",
    "            \n",
    "        uniqueLabels = set(classes)\n",
    "        if len(uniqueLabels)==1:\n",
    "            return DecisionNode(None, None, None, uniqueLabels.pop())\n",
    "        \n",
    "        bestIG = 0\n",
    "        bestAttr = 0\n",
    "        bestAttrSplit = 0\n",
    "        bestLeftIndex = []\n",
    "        sampledAttr = []\n",
    "        #serially checking each attribute for IG\n",
    "        if mode==1:\n",
    "            sampledAttr = list(numpy.random.choice(range(len(features[0])), len(features[0])*attr_subsample_rate))\n",
    "            #print sampledAttr\n",
    "        for i in range(self.numAttr):\n",
    "            if mode==0 or (mode==1 and i in sampledAttr):\n",
    "                #print [mode, i]\n",
    "                allAttrValues = [featVector[i] for featVector in features]\n",
    "                minAttrValue = min(allAttrValues)\n",
    "                maxAttrValue = max(allAttrValues)\n",
    "                #print [minAttrValue, maxAttrValue]\n",
    "                split = minAttrValue\n",
    "                step = (maxAttrValue-minAttrValue)/100\n",
    "                bestSplitIG = 0\n",
    "                bestSplit = 0\n",
    "                bestSplitLeftIndex = []\n",
    "                #checking IG on different splits\n",
    "                while split<=maxAttrValue:\n",
    "                    classSplitLeft = []\n",
    "                    classSplitRight = []\n",
    "                    indxLeft  = []\n",
    "                    j=0\n",
    "                    for attValue in allAttrValues:\n",
    "                        #print [attValue, j, classes[j]]\n",
    "                        if attValue<split:\n",
    "                            classSplitLeft.append(classes[j])\n",
    "                            indxLeft.append(j)\n",
    "                        else:\n",
    "                            classSplitRight.append(classes[j])\n",
    "                        j += 1\n",
    "                    if len(classSplitLeft)>0 and len(classSplitRight)>0:\n",
    "                        IG = information_gain(classes,[classSplitLeft,classSplitRight])\n",
    "                        if IG>bestSplitIG:\n",
    "                            bestSplitIG = IG\n",
    "                            bestSplit = split\n",
    "                            bestSplitLeftIndex = list(indxLeft)\n",
    "                    split += step\n",
    "                #checking if this attribute is the best or not    \n",
    "                if bestSplitIG>bestIG:\n",
    "                    bestIG = bestSplitIG\n",
    "                    bestAttr = i\n",
    "                    bestAttrSplit = bestSplit\n",
    "                    bestLeftIndex = list(bestSplitLeftIndex)\n",
    "                #print str(['depth: ',depth,' bestIG: ', bestIG, 'bestAttr: ',bestAttr,' bestSplit: ', bestSplit])\n",
    "            #now we have the index of the best attribute by maximizing on the IG\n",
    "            #self.ignoreAttr.append(bestAttr)\n",
    "        #construct feature and class label lists for left and right tree\n",
    "        leftFeatures = []\n",
    "        leftClasses = []\n",
    "        rightFeatures = []\n",
    "        rightClasses = []\n",
    "        for i in range(len(features)):\n",
    "            if i in bestLeftIndex:\n",
    "                leftFeatures.append(features[i])\n",
    "                leftClasses.append(classes[i])\n",
    "            else:\n",
    "                rightFeatures.append(features[i])\n",
    "                rightClasses.append(classes[i])\n",
    "        decFunc = lambda feat: feat[bestAttr]<bestAttrSplit\n",
    "        if mode==0:\n",
    "            return DecisionNode(self.__build_tree__(leftFeatures,leftClasses, depth+1),self.__build_tree__(rightFeatures,rightClasses,depth+1), decFunc)\n",
    "        else:\n",
    "            #print str(['best split on depth:',depth,'. Split:', bestAttrSplit,'. Length of left and right',len(leftFeatures),' ', len(rightFeatures)]) \n",
    "            return DecisionNode(self.__build_tree__(leftFeatures,leftClasses, depth+1,1,attr_subsample_rate),self.__build_tree__(rightFeatures,rightClasses,depth+1,1,attr_subsample_rate), decFunc)\n",
    "    \n",
    "        \n",
    "    def classify(self, features):\n",
    "        #TODO Use a fitted tree to classify a list of feature vectors\n",
    "        # Your output should be a list of class labels (either 0 or 1)\n",
    "        labels = [0 for i in features]\n",
    "        for i in range(len(features)):\n",
    "            labels[i] = self.root.decide(features[i])\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2b: Validation\n",
    "--------\n",
    "\n",
    "For this part of the assignment we're going to use a relatively simple dataset (banknote authentication, found in 'part_2_data.csv'. In the section below there are methods to load the data in a consistent format.\n",
    "\n",
    "In general, reserving part of your data as a test set can lead to unpredictable performance- a serendipitous choice of your train or test split could give you a very inaccurate idea of how your classifier performs. That's where k-fold cross validation comes in.\n",
    "\n",
    "In the below method, we'll split the dataset at random into k equal subsections, then iterating on each of our k samples, we'll reserve that sample for testing and use the other k-1 for training. Averaging the results of each fold should give us a more consistent idea of how the classifier is doing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.5547445255\n",
      "62.1258714106\n",
      "99.8076923077\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy\n",
    "def load_csv(data_file_path, class_index=-1):\n",
    "    handle = open(data_file_path, 'r')\n",
    "    contents = handle.read()\n",
    "    handle.close()\n",
    "    rows = contents.split('\\n')\n",
    "    out = numpy.array([  [float(i) for i in r.split(',')] for r in rows if r ])\n",
    "    classes= map(int,  out[:, class_index])\n",
    "    features = out[:, :class_index]\n",
    "    return features, classes\n",
    "\n",
    "def generate_k_folds(dataset, k):\n",
    "    #TODO this method should return a list of folds,\n",
    "    # where each fold is a tuple like (training_set, test_set)\n",
    "    # where each set is a tuple like (examples, classes)\n",
    "    kFolds = []\n",
    "    numTraining = int(len(dataset[1])/k)\n",
    "    for i in range(k):\n",
    "        testFeat = []\n",
    "        testClasses = []\n",
    "        trainingFeat = []\n",
    "        trainingClasses = []\n",
    "        testIndx = random.sample(range(len(dataset[1])),numTraining)\n",
    "        for j in range(len(dataset[0])):\n",
    "            if j in testIndx:\n",
    "                testFeat.append(dataset[0][j])\n",
    "                testClasses.append(dataset[1][j])\n",
    "            else:\n",
    "                trainingFeat.append(dataset[0][j])\n",
    "                trainingClasses.append(dataset[1][j])\n",
    "        kFolds.append([[trainingFeat, trainingClasses],[testFeat, testClasses]])\n",
    "    \n",
    "    return kFolds\n",
    "\n",
    "dataset = load_csv('part2_data.csv')\n",
    "ten_folds = generate_k_folds(dataset, 10)\n",
    "\n",
    "#on average your accuracy should be higher than 60%.\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "confusion = []\n",
    "\n",
    "for fold in ten_folds:\n",
    "    train, test = fold\n",
    "    train_features, train_classes = train\n",
    "    test_features, test_classes = test\n",
    "    tree = DecisionTree(1)\n",
    "    tree.fit( train_features, train_classes)\n",
    "    output = tree.classify(test_features)\n",
    "    #print output\n",
    "    \n",
    "    accuracies.append( accuracy(output, test_classes))\n",
    "    precisions.append( precision(output, test_classes))\n",
    "    recalls.append( recall(output, test_classes))\n",
    "    confusion.append( confusion_matrix(output, test_classes))\n",
    "    \n",
    "print sum(accuracies)*10\n",
    "print sum(precisions)*10\n",
    "print sum(recalls)*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Random Forests\n",
    "-------\n",
    "30 pts.\n",
    "\n",
    "The decision boundaries drawn by decision trees are very sharp, and fitting a decision tree of unbounded depth to a list of examples almost inevitably leads to overfitting. In an attempt to decrease the variance of our classifier we're going to use a technique called 'Bootstrap Aggregating' (often abbreviated 'bagging').\n",
    "\n",
    "A Random Forest is a collection of decision trees, built as follows:\n",
    "\n",
    "1) For every tree we're going to build:\n",
    "\n",
    "    a) Subsample the examples provided us (with replacement) in accordance with a provided example subsampling rate.\n",
    "    \n",
    "    b) From the sample in a), choose attributes at random to learn on (in accordance with a provided attribute subsampling rate)\n",
    "    \n",
    "    c) Fit a decision tree to the subsample of data we've chosen (to a certain depth)\n",
    "    \n",
    "Classification for a random forest is then done by taking a majority vote of the classifications yielded by each tree in the forest after it classifies an example.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.1897810219\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "class RandomForest():\n",
    "\n",
    "    def __init__(self, num_trees, depth_limit, example_subsample_rate, attr_subsample_rate):\n",
    "        self.trees = []\n",
    "        self.num_trees = num_trees\n",
    "        self.depth_limit = depth_limit\n",
    "        self.example_subsample_rate = example_subsample_rate\n",
    "        self.attr_subsample_rate = attr_subsample_rate\n",
    "\n",
    "    def fit(self, features, classes):\n",
    "        #assuming data and attr subsample rate to be a fraction\n",
    "        #create 5 different subsamples of data and attr and then fit 5 different DTs\n",
    "        \n",
    "        for i in range(self.num_trees):\n",
    "            trainingIdx = numpy.random.choice(range(len(features)),len(features)*self.example_subsample_rate)\n",
    "            trainingFeat = [features[i] for i in trainingIdx]\n",
    "            trainingClass = [classes[i] for i in trainingIdx]\n",
    "            tree = DecisionTree(self.depth_limit)\n",
    "            tree.numAttr = len(features[0])\n",
    "            tree.root = tree.__build_tree__(features, classes, 0, 1, self.attr_subsample_rate)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "            \n",
    "    def classify(self, features):\n",
    "        #get decisions from each DT and then count votes for each label\n",
    "        count = [[0,0] for i in range(len(features))]\n",
    "        for i in range(self.num_trees):\n",
    "            label = self.trees[i].classify(features)\n",
    "            i=0\n",
    "            for l in label:\n",
    "                count[i][l] +=1\n",
    "                i += 1\n",
    "        classes = [0 if count[i][0]>count[i][1] else 1 for i in range(len(features))]\n",
    "        return classes\n",
    "    \n",
    "#TODO: As with the DecisionTree, evaluate the performance of your RandomForest on the dataset for part 2.\n",
    "# on average your accuracy should be higher than 75%.\n",
    "\n",
    "#  Optimize the parameters of your random forest for accuracy for a forest of 5 trees.\n",
    "# (We'll verify these by training one of your RandomForest instances using these parameters\n",
    "#  and checking the resulting accuracy)\n",
    "\n",
    "#  Fill out the function below to reflect your answer:\n",
    "\n",
    "\n",
    "dataset = load_csv('part2_data.csv')\n",
    "ten_folds = generate_k_folds(dataset, 10)\n",
    "\n",
    "bestAcc = 0\n",
    "bestPrec = 0\n",
    "bestRecall = 0\n",
    "bestI = 0\n",
    "bestJ = 0\n",
    "i=0.1\n",
    "stepData = 0.1\n",
    "stepAttr = 0.25\n",
    "'''while i<1:\n",
    "    j = 0.75\n",
    "    while j<=1:\n",
    "        print [i,j]'''\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "confusion = []\n",
    "for fold in ten_folds:\n",
    "    train, test = fold\n",
    "    train_features, train_classes = train\n",
    "    test_features, test_classes = test\n",
    "    RF = RandomForest(5,1,0.1,0.25)\n",
    "    RF.fit(train_features, train_classes)\n",
    "    output = RF.classify(test_features)\n",
    "    #print zip(output, test_classes)\n",
    "\n",
    "    accuracies.append( accuracy(output, test_classes))\n",
    "    precisions.append( precision(output, test_classes))\n",
    "    recalls.append( recall(output, test_classes))\n",
    "    confusion.append( confusion_matrix(output, test_classes))\n",
    "\n",
    "avgAcc = sum(accuracies)*10\n",
    "avgPrec = sum(precisions)*10\n",
    "avgRec = sum(recalls)*10\n",
    "'''if avgAcc>bestAcc:\n",
    "            bestAcc = avgAcc\n",
    "            bestPrec = avgPrec\n",
    "            bestRecall = avgRec\n",
    "            bestI = i\n",
    "            bestJ = j\n",
    "        j += stepAttr\n",
    "    i += stepData'''        \n",
    "\n",
    "#print [bestAcc,bestPrec,bestRecall,bestI, bestJ]\n",
    "print avgAcc\n",
    "def ideal_parameters():\n",
    "    return 1, 0.1, 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Challenge!\n",
    "-------\n",
    "10 pts\n",
    "\n",
    "You've been provided with a sample of data from a research dataset in 'challenge_data.pickle'. It is serialized as a tuple of (features, classes). I have reserved a part of the dataset for testing. The classifier that performs most accurately on the holdout set wins (so optimize for accuracy). To get full points for this part of the assignment, you'll need to get at least an average accuracy of 80% on the data you have, and at least an average accuracy of 60% on the holdout set.\n",
    "\n",
    "Ties will be broken by submission time.\n",
    "\n",
    "First place:  +3% on your final grade\n",
    "\n",
    "Second place: +2% on your final grade\n",
    "\n",
    "Third place:  +1% on your final grade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ChallengeClassifier():\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialize whatever parameters you may need here-\n",
    "        # this method will be called without parameters \n",
    "        # so if you add any to make parameter sweeps easier, provide defaults\n",
    "        raise NotImplemented()\n",
    "        \n",
    "    def fit(self, features, classes):\n",
    "        # fit your model to the provided features\n",
    "        raise NotImplemented()\n",
    "        \n",
    "    def classify(self, features):\n",
    "        # classify each feature in features as either 0 or 1.\n",
    "        raise NotImplemented()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
